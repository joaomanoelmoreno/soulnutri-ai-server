"""
SoulNutri - Servi√ßo de IA Gen√©rica para Identifica√ß√£o e Informa√ß√µes Nutricionais
Foco: Informa√ß√µes RELEVANTES, CIENT√çFICAS e RECENTES que o cliente N√ÉO conhece
"""

import os
import base64
import json
import tempfile
from dotenv import load_dotenv
from emergentintegrations.llm.chat import LlmChat, UserMessage, FileContentWithMimeType

load_dotenv()

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# PROMPT PRINCIPAL - IDENTIFICA√á√ÉO R√ÅPIDA DE PRATOS
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

SYSTEM_PROMPT_IDENTIFY = """Identifique o prato na imagem.

CONTEXTO: Este √© um buffet de restaurante brasileiro. Os pratos comuns incluem:
- Arroz (branco, integral, 7 gr√£os), Feij√£o (preto, carioca)
- Espaguete, Lasanha, Canelone, Macarr√£o
- Frango grelhado, Frango √† parmegiana, Fil√© mignon, Maminha
- Peixe, Salm√£o, Atum, Bacalhau (√† br√°s, com natas, √† gomes de s√°)
- Bolinho de bacalhau, Cestinha de camar√£o
- Saladas, Legumes, Batata (doce, assada, frita)
- Cocada, Gelatina, Mousse, Pudim

REGRAS DE CATEGORIA:
- "vegano": ZERO produtos de origem animal
- "vegetariano": tem ovo/leite/queijo de VACA, SEM carne
- "prote√≠na animal": tem carne/peixe/frango

INGREDIENTES VEGANOS (N√ÉO s√£o de origem animal):
- Leite de coco, creme de coco, √≥leo de coco
- Leite de am√™ndoas, leite de soja, leite de aveia
- Cogumelos, tofu, tempeh, seitan

ATEN√á√ÉO CR√çTICA:
- Peixe/camar√£o/mariscos = prote√≠na animal
- Ovo/queijo de VACA/leite de VACA = vegetariano (n√£o vegano)
- Bacon/presunto/carne = prote√≠na animal
- Leite de COCO = VEGANO (n√£o √© de origem animal!)
- Muqueca com leite de coco e SEM peixe = vegano

Use nomes simples em portugu√™s. Exemplo: "Bolinho de Bacalhau" (n√£o "codfish balls").

JSON obrigat√≥rio:
{
    "nome": "Nome do Prato",
    "categoria": "vegano|vegetariano|prote√≠na animal",
    "confianca": "alta|m√©dia|baixa",
    "score": 0.9,
    "ingredientes_provaveis": ["ing1", "ing2", "ing3"],
    "beneficio_principal": "Benef√≠cio principal",
    "curiosidade_cientifica": "Fato interessante",
    "riscos": ["Al√©rgeno: X"],
    "descricao": "Descri√ß√£o curta"
}"""


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# PROMPT PARA M√öLTIPLOS ITENS NO PRATO
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

SYSTEM_PROMPT_MULTI_ITEM = """Identifique TODOS os itens vis√≠veis no prato.

Para cada item, retorne:
- nome: Nome do item
- categoria: "vegano" | "vegetariano" | "prote√≠na animal"
- ingredientes: Lista de ingredientes vis√≠veis

REGRAS:
- Peixe/carne/frango = prote√≠na animal
- Ovo/queijo = vegetariano
- S√≥ vegetais/gr√£os = vegano

JSON obrigat√≥rio:
{
    "total_itens": 3,
    "itens": [
        {"nome": "Arroz", "categoria": "vegano", "ingredientes": ["arroz"], "calorias": "~150kcal"},
        {"nome": "Feij√£o", "categoria": "vegano", "ingredientes": ["feij√£o"], "calorias": "~100kcal"}
    ],
    "calorias_totais": "~500kcal",
    "alertas": ["Al√©rgeno: X"]
}"""


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# PROMPT PARA ENRIQUECER INFORMA√á√ïES DE PRATOS EXISTENTES
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

SYSTEM_PROMPT_ENRICH = """Voc√™ √© o SoulNutri, especialista em nutri√ß√£o baseada em evid√™ncias cient√≠ficas.

Sua tarefa √© ENRIQUECER as informa√ß√µes de um prato brasileiro com dados RELEVANTES e CIENT√çFICOS.

REGRAS:
1. N√ÉO use informa√ß√µes √≥bvias (colesterol faz mal, a√ß√∫car engorda)
2. CITE fontes cient√≠ficas (OMS, ANVISA, estudos)
3. EXPLIQUE por que cada nutriente √© importante para o corpo
4. ALERTE sobre riscos baseados em pesquisas recentes
5. INCLUA curiosidades cient√≠ficas que surpreendem

Retorne JSON com:
{
    "beneficio_principal": "Benef√≠cio mais relevante COM DADOS e explica√ß√£o do efeito no corpo",
    "alerta_saude": "Alerta cient√≠fico relevante OU null se n√£o houver",
    "curiosidade_cientifica": "Fato surpreendente baseado em pesquisa",
    "beneficios": ["benef√≠cio 1 com dados", "benef√≠cio 2"],
    "riscos": ["risco relevante se houver"],
    "referencia_pesquisa": "Fonte cient√≠fica principal"
}"""


async def identify_unknown_dish(image_bytes: bytes) -> dict:
    """
    Identifica um prato desconhecido usando Gemini Vision.
    OTIMIZADO para velocidade: comprime imagem antes de enviar.
    """
    try:
        api_key = os.environ.get('EMERGENT_LLM_KEY')
        if not api_key:
            return {"ok": False, "error": "EMERGENT_LLM_KEY n√£o configurada"}
        
        # OTIMIZA√á√ÉO: Comprimir imagem para envio mais r√°pido
        from PIL import Image
        import io
        
        img = Image.open(io.BytesIO(image_bytes))
        
        # Redimensionar para menor tamanho (max 512px - mais r√°pido)
        max_size = 512
        if max(img.size) > max_size:
            ratio = max_size / max(img.size)
            new_size = (int(img.size[0] * ratio), int(img.size[1] * ratio))
            img = img.resize(new_size, Image.LANCZOS)
        
        # Converter para RGB se necess√°rio
        if img.mode != 'RGB':
            img = img.convert('RGB')
        
        # Salvar com compress√£o alta (mais r√°pido upload)
        buffer = io.BytesIO()
        img.save(buffer, format='JPEG', quality=60, optimize=True)
        compressed_bytes = buffer.getvalue()
        
        # Salvar arquivo tempor√°rio
        with tempfile.NamedTemporaryFile(suffix='.jpg', delete=False) as tmp_file:
            tmp_file.write(compressed_bytes)
            tmp_path = tmp_file.name
        
        try:
            chat = LlmChat(
                api_key=api_key,
                session_id=f"dish-{id(image_bytes)}",
                system_message=SYSTEM_PROMPT_IDENTIFY
            ).with_model("gemini", "gemini-2.0-flash-lite")
            
            image_file = FileContentWithMimeType(
                file_path=tmp_path,
                mime_type="image/jpeg"
            )
            
            user_message = UserMessage(
                text="Identifique este prato. Responda APENAS JSON.",
                file_contents=[image_file]
            )
            
            response = await chat.send_message(user_message)
        finally:
            if os.path.exists(tmp_path):
                os.remove(tmp_path)
        
        # Parse JSON
        response_clean = response.strip()
        if response_clean.startswith("```"):
            response_clean = response_clean.split("```")[1]
            if response_clean.startswith("json"):
                response_clean = response_clean[4:]
        response_clean = response_clean.strip()
        
        try:
            result = json.loads(response_clean)
            result["ok"] = True
            result["source"] = "generic_ai"
            
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # VALIDA√á√ÉO DE SEGURAN√áA - Corrige classifica√ß√µes erradas
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            from services.safety_validator import validar_resultado_ia
            result = validar_resultado_ia(result)
            
            # Mapear confian√ßa
            conf_map = {"alta": "üü¢", "m√©dia": "üü°", "baixa": "üî¥"}
            result["confidence_emoji"] = conf_map.get(result.get("confianca", "baixa"), "üî¥")
            
            # Mapear categoria (ap√≥s valida√ß√£o de seguran√ßa)
            cat_map = {"vegano": "üå±", "vegetariano": "ü•¨", "prote√≠na animal": "üçñ"}
            result["category_emoji"] = cat_map.get(result.get("categoria", ""), "üçΩÔ∏è")
            
            return result
            
        except json.JSONDecodeError:
            return {
                "ok": True,
                "source": "generic_ai",
                "raw_response": response,
                "nome": "Prato n√£o identificado",
                "confianca": "baixa",
                "score": 0.3
            }
            
    except Exception as e:
        return {"ok": False, "error": str(e), "source": "generic_ai"}


async def enrich_dish_info(dish_name: str, ingredients: list = None) -> dict:
    """
    Enriquece informa√ß√µes de um prato com dados cient√≠ficos.
    Usado para melhorar pratos existentes no banco.
    """
    try:
        api_key = os.environ.get('EMERGENT_LLM_KEY')
        if not api_key:
            return {}
        
        chat = LlmChat(
            api_key=api_key,
            session_id=f"enrich-{dish_name}",
            system_message=SYSTEM_PROMPT_ENRICH
        ).with_model("openai", "gpt-4o-mini")
        
        ingredients_text = ", ".join(ingredients) if ingredients else "n√£o especificados"
        
        prompt = f"""Enrique√ßa as informa√ß√µes deste prato brasileiro com dados CIENT√çFICOS:

Prato: {dish_name}
Ingredientes: {ingredients_text}

Forne√ßa:
1. Benef√≠cio principal com DADOS (mg, %, estudos)
2. Alerta de sa√∫de SE houver pesquisa relevante
3. Curiosidade cient√≠fica surpreendente
4. Refer√™ncia da fonte principal"""
        
        response = await chat.send_message(UserMessage(text=prompt))
        
        response_clean = response.strip()
        if response_clean.startswith("```"):
            response_clean = response_clean.split("```")[1]
            if response_clean.startswith("json"):
                response_clean = response_clean[4:]
        
        return json.loads(response_clean.strip())
        
    except Exception as e:
        print(f"Erro ao enriquecer {dish_name}: {e}")
        return {}


async def search_ingredient_news(ingredient: str) -> dict:
    """
    Busca not√≠cias/pesquisas recentes sobre um ingrediente.
    
    PROTE√á√ÉO CONTRA FAKE NEWS:
    - Usa apenas fontes cient√≠ficas verificadas
    - Inclui data da pesquisa
    - Valida informa√ß√µes com m√∫ltiplas fontes
    """
    try:
        api_key = os.environ.get('EMERGENT_LLM_KEY')
        if not api_key:
            return {}
        
        chat = LlmChat(
            api_key=api_key,
            session_id=f"news-{ingredient}",
            system_message="""Voc√™ √© um pesquisador de nutri√ß√£o RIGOROSO. Forne√ßa APENAS informa√ß√µes de pesquisas VERIFICADAS.

üîí REGRAS ANTI-FAKE NEWS (OBRIGAT√ìRIAS):
1. Use APENAS fontes cient√≠ficas oficiais:
   - OMS (Organiza√ß√£o Mundial da Sa√∫de)
   - ANVISA (Brasil)
   - FDA (EUA)
   - EFSA (Europa)
   - PubMed / NIH
   - Revistas cient√≠ficas peer-reviewed (Nature, Lancet, JAMA, etc.)

2. NUNCA cite:
   - Blogs pessoais
   - Redes sociais
   - Sites de not√≠cias sensacionalistas
   - Estudos n√£o revisados por pares
   - Fontes sem data ou autor

3. Sempre inclua:
   - ANO do estudo/publica√ß√£o
   - NOME da institui√ß√£o ou revista
   - Se √© CONSENSO cient√≠fico ou estudo PRELIMINAR

4. Se N√ÉO houver pesquisa confi√°vel, diga claramente:
   "N√£o h√° estudos cient√≠ficos robustos sobre este t√≥pico"

Retorne JSON:
{
    "ingrediente": "nome",
    "pesquisa_verificada": "Descri√ß√£o factual da pesquisa",
    "fonte_oficial": "OMS 2023 / Estudo Harvard publicado no JAMA / etc",
    "nivel_evidencia": "consenso" | "forte" | "moderado" | "preliminar",
    "data_pesquisa": "2023" ou "2024",
    "impacto_saude": "O que isso significa para o consumidor",
    "recomendacao_oficial": "Recomenda√ß√£o baseada em √≥rg√£o oficial",
    "aviso": "Informa√ß√£o importante sobre limita√ß√µes do estudo, se houver"
}"""
        ).with_model("openai", "gpt-4o-mini")
        
        response = await chat.send_message(UserMessage(
            text=f"""Busque pesquisas cient√≠ficas VERIFICADAS sobre: {ingredient}

IMPORTANTE:
- Apenas estudos de fontes oficiais (OMS, ANVISA, FDA, revistas cient√≠ficas)
- Inclua ano e fonte exata
- Indique se √© consenso ou estudo preliminar
- Se n√£o houver evid√™ncia forte, seja honesto sobre isso"""
        ))
        
        response_clean = response.strip()
        if response_clean.startswith("```"):
            response_clean = response_clean.split("```")[1]
            if response_clean.startswith("json"):
                response_clean = response_clean[4:]
        
        result = json.loads(response_clean.strip())
        result["fonte_verificada"] = True
        result["aviso_padrao"] = "Informa√ß√µes baseadas em pesquisas cient√≠ficas. Consulte um profissional de sa√∫de para orienta√ß√£o personalizada."
        
        return result
        
    except Exception as e:
        return {"error": str(e), "fonte_verificada": False}


async def identify_multiple_items(image_bytes: bytes) -> dict:
    """
    Identifica M√öLTIPLOS itens em uma imagem de refei√ß√£o.
    √ötil para buffets, pratos compostos ou refei√ß√µes com v√°rios componentes.
    """
    try:
        api_key = os.environ.get('EMERGENT_LLM_KEY')
        if not api_key:
            return {"ok": False, "error": "EMERGENT_LLM_KEY n√£o configurada"}
        
        with tempfile.NamedTemporaryFile(suffix='.jpg', delete=False) as tmp_file:
            tmp_file.write(image_bytes)
            tmp_path = tmp_file.name
        
        try:
            chat = LlmChat(
                api_key=api_key,
                session_id=f"multi-item-{id(image_bytes)}",
                system_message=SYSTEM_PROMPT_MULTI_ITEM
            ).with_model("gemini", "gemini-2.0-flash")
            
            image_file = FileContentWithMimeType(
                file_path=tmp_path,
                mime_type="image/jpeg"
            )
            
            user_message = UserMessage(
                text="Analise esta imagem e identifique TODOS os itens/pratos separadamente. Se for um buffet ou prato composto, liste cada componente. Responda APENAS com JSON v√°lido.",
                file_contents=[image_file]
            )
            
            response = await chat.send_message(user_message)
        finally:
            if os.path.exists(tmp_path):
                os.remove(tmp_path)
        
        # Parse JSON
        response_clean = response.strip()
        if response_clean.startswith("```"):
            response_clean = response_clean.split("```")[1]
            if response_clean.startswith("json"):
                response_clean = response_clean[4:]
        response_clean = response_clean.strip()
        
        try:
            result = json.loads(response_clean)
            result["ok"] = True
            result["source"] = "generic_ai_multi"
            return result
        except json.JSONDecodeError:
            return {
                "ok": False,
                "error": "Erro ao processar resposta da IA",
                "raw_response": response
            }
            
    except Exception as e:
        return {"ok": False, "error": str(e)}


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# PROMPT PARA CORRE√á√ÉO/PREENCHIMENTO DE DADOS DO PRATO
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

SYSTEM_PROMPT_FIX_DISH = """Voc√™ √© um nutricionista RIGOROSO analisando dados de pratos.

TAREFA: Analisar a imagem do prato e PREENCHER/CORRIGIR as informa√ß√µes faltantes.

REGRAS ESTRITAS DE CATEGORIA:
1. "vegano": ZERO ingredientes de origem animal (sem ovo, leite de VACA, queijo, mel)
2. "vegetariano": pode ter ovo, leite de VACA, queijo, mel, MAS sem carne/peixe/frango
3. "prote√≠na animal": cont√©m carne, peixe, frango, bacon, presunto, camar√£o

IMPORTANTE - INGREDIENTES VEGANOS:
- Leite de COCO = VEGANO (n√£o √© de origem animal!)
- Creme de coco, √≥leo de coco = VEGANO
- Leite de am√™ndoas, soja, aveia = VEGANO
- Cogumelos, tofu, tempeh = VEGANO
- Muqueca com leite de coco SEM peixe = VEGANO

REGRAS DE NUTRI√á√ÉO (por por√ß√£o ~100g):
- Vegetais: 20-50 kcal
- Arroz/massa: 130-160 kcal
- Carnes magras: 150-200 kcal
- Frituras: 250-400 kcal

AL√âRGENOS - Marque TRUE apenas se CERTEZA:
- contem_gluten: farinha de trigo, p√£o, massa, empanado
- contem_lactose: leite de VACA, queijo, creme de leite, manteiga
- contem_ovo: ovos, maionese, massas com ovo
- contem_castanhas: castanhas, amendoim, nozes, am√™ndoas
- contem_frutos_mar: camar√£o, peixe, mariscos
- contem_soja: tofu, shoyu, leite de soja

RESPONDA APENAS JSON:
{
    "nome": "Nome Correto do Prato",
    "categoria": "vegano|vegetariano|prote√≠na animal",
    "category_emoji": "ü•¨|ü•ö|üçñ",
    "descricao": "Descri√ß√£o em 1-2 frases",
    "ingredientes": ["ingrediente1", "ingrediente2"],
    "beneficios": ["benef√≠cio1", "benef√≠cio2"],
    "riscos": ["Cont√©m X (al√©rgeno)", "Alto teor de Y"],
    "nutricao": {
        "calorias": "XXX kcal",
        "proteinas": "XXg",
        "carboidratos": "XXg",
        "gorduras": "XXg"
    },
    "contem_gluten": true/false,
    "contem_lactose": true/false,
    "contem_ovo": true/false,
    "contem_castanhas": true/false,
    "contem_frutos_mar": true/false,
    "contem_soja": true/false
}"""


async def fix_dish_data_with_ai(image_bytes: bytes, current_info: dict) -> dict:
    """
    Usa Gemini para corrigir/preencher dados de um prato.
    Envia a imagem + dados atuais e pede para corrigir/completar.
    """
    import tempfile
    
    try:
        api_key = os.environ.get("EMERGENT_LLM_KEY")
        if not api_key:
            return {"ok": False, "error": "EMERGENT_LLM_KEY n√£o configurada"}
        
        with tempfile.NamedTemporaryFile(suffix='.jpg', delete=False) as tmp_file:
            tmp_file.write(image_bytes)
            tmp_path = tmp_file.name
        
        try:
            chat = LlmChat(
                api_key=api_key,
                session_id=f"fix-dish-{id(image_bytes)}",
                system_message=SYSTEM_PROMPT_FIX_DISH
            ).with_model("gemini", "gemini-2.0-flash")
            
            image_file = FileContentWithMimeType(
                file_path=tmp_path,
                mime_type="image/jpeg"
            )
            
            # Preparar contexto dos dados atuais
            context = f"""DADOS ATUAIS DO PRATO (podem estar incorretos ou incompletos):
Nome: {current_info.get('nome', 'N√ÉO DEFINIDO')}
Categoria: {current_info.get('categoria', 'N√ÉO DEFINIDA')}
Ingredientes: {current_info.get('ingredientes', [])}
Nutri√ß√£o: {current_info.get('nutricao', {})}

ANALISE A IMAGEM e CORRIJA/COMPLETE todos os campos.
Se o nome atual contiver "Unknown", d√™ o nome correto.
Se nutri√ß√£o estiver vazia, preencha com valores realistas.
Responda APENAS com JSON v√°lido."""
            
            user_message = UserMessage(
                text=context,
                file_contents=[image_file]
            )
            
            response = await chat.send_message(user_message)
        finally:
            if os.path.exists(tmp_path):
                os.remove(tmp_path)
        
        # Parse JSON
        response_clean = response.strip()
        if response_clean.startswith("```"):
            response_clean = response_clean.split("```")[1]
            if response_clean.startswith("json"):
                response_clean = response_clean[4:]
        response_clean = response_clean.strip()
        
        try:
            result = json.loads(response_clean)
            result["ok"] = True
            return result
        except json.JSONDecodeError:
            return {
                "ok": False,
                "error": "Erro ao processar resposta da IA",
                "raw_response": response
            }
            
    except Exception as e:
        return {"ok": False, "error": str(e)}


async def batch_fix_dishes(slugs: list, max_concurrent: int = 3) -> dict:
    """
    Corrige m√∫ltiplos pratos em lote.
    """
    import asyncio
    from pathlib import Path
    
    results = {"fixed": [], "failed": [], "skipped": []}
    dataset_dir = Path("/app/datasets/organized")
    
    async def fix_single(slug: str) -> dict:
        dish_dir = dataset_dir / slug
        info_path = dish_dir / "dish_info.json"
        
        # Carregar info atual
        current_info = {}
        if info_path.exists():
            try:
                with open(info_path, 'r', encoding='utf-8') as f:
                    current_info = json.load(f)
            except:
                pass
        
        # Buscar imagem
        images = list(dish_dir.glob("*.jpg")) + list(dish_dir.glob("*.jpeg"))
        if not images:
            return {"slug": slug, "status": "skipped", "reason": "sem imagem"}
        
        # Ler imagem
        with open(images[0], 'rb') as f:
            image_bytes = f.read()
        
        # Chamar IA
        result = await fix_dish_data_with_ai(image_bytes, current_info)
        
        if result.get("ok"):
            # Salvar resultado
            new_info = {**current_info, **result}
            new_info.pop("ok", None)
            new_info["slug"] = slug
            
            with open(info_path, 'w', encoding='utf-8') as f:
                json.dump(new_info, f, ensure_ascii=False, indent=2)
            
            return {"slug": slug, "status": "fixed", "data": new_info}
        else:
            return {"slug": slug, "status": "failed", "error": result.get("error")}
    
    # Processar em lotes
    for i in range(0, len(slugs), max_concurrent):
        batch = slugs[i:i+max_concurrent]
        batch_results = await asyncio.gather(*[fix_single(s) for s in batch])
        
        for r in batch_results:
            if r["status"] == "fixed":
                results["fixed"].append(r["slug"])
            elif r["status"] == "failed":
                results["failed"].append({"slug": r["slug"], "error": r.get("error")})
            else:
                results["skipped"].append({"slug": r["slug"], "reason": r.get("reason")})
    
    return results


async def regenerate_dish_info_from_name(dish_name: str, old_info: dict = None) -> dict:
    """
    Regenera TODAS as informa√ß√µes de um prato baseado apenas no NOME.
    √ötil quando o usu√°rio corrige o nome de um prato (ex: de "Peixe" para "Batata").
    
    IMPORTANTE: Esta fun√ß√£o gera informa√ß√µes CONSISTENTES com o novo nome,
    atualizando ingredientes, nutri√ß√£o, categoria, etc.
    """
    try:
        api_key = os.environ.get("EMERGENT_LLM_KEY")
        if not api_key:
            return {"ok": False, "error": "EMERGENT_LLM_KEY n√£o configurada"}
        
        chat = LlmChat(
            api_key=api_key,
            session_id=f"regen-{dish_name}",
            system_message="""Voc√™ √© um nutricionista especializado em gastronomia brasileira.
Seu trabalho √© CRIAR uma ficha t√©cnica COMPLETA e PRECISA para um prato baseado apenas no nome.

REGRAS CR√çTICAS:
1. CATEGORIA CORRETA:
   - "vegano": ZERO produtos animais (nem ovo, nem leite, nem mel)
   - "vegetariano": pode ter ovo/leite/queijo de VACA, mas SEM carne/peixe/frango
   - "prote√≠na animal": tem carne/peixe/frango/crust√°ceos
   
2. INGREDIENTES VEGANOS (N√ÉO s√£o de origem animal):
   - Leite de coco, creme de coco = VEGANO
   - Queijo vegano, queijo de castanha = VEGANO
   - Cogumelos, tofu = VEGANO
   
3. INGREDIENTES DE ORIGEM ANIMAL:
   - Queijo (sem especificar "vegano") = LACTOSE
   - Leite (sem especificar "vegetal") = LACTOSE
   - Maionese tradicional = cont√©m OVO
   
4. DECORA√á√ÉO n√£o conta como ingrediente principal

5. Use valores nutricionais REALISTAS (por 100g):
   - Calorias: em kcal
   - Prote√≠nas: em g
   - Carboidratos: em g
   - Gorduras: em g

Responda APENAS com JSON v√°lido no formato:
{
    "nome": "Nome do Prato",
    "categoria": "vegano|vegetariano|prote√≠na animal",
    "descricao": "Descri√ß√£o detalhada do prato",
    "ingredientes": ["ingrediente1", "ingrediente2", ...],
    "beneficios": ["benef√≠cio1", "benef√≠cio2", ...],
    "riscos": ["risco1", "risco2", ...],
    "nutricao": {
        "calorias": "XXX kcal",
        "proteinas": "XXg",
        "carboidratos": "XXg",
        "gorduras": "XXg"
    },
    "contem_gluten": true/false,
    "contem_lactose": true/false,
    "contem_ovo": true/false,
    "contem_castanhas": true/false,
    "contem_frutos_mar": true/false,
    "contem_soja": true/false,
    "tecnica": "T√©cnica de preparo"
}"""
        ).with_model("gemini", "gemini-2.0-flash")
        
        context = f"""Gere a ficha t√©cnica COMPLETA para este prato:

NOME DO PRATO: {dish_name}

INFORMA√á√ïES ANTIGAS (podem estar ERRADAS - use apenas como refer√™ncia):
{json.dumps(old_info, ensure_ascii=False, indent=2) if old_info else "Nenhuma"}

IMPORTANTE: Baseie-se NO NOME do prato para determinar ingredientes e categoria.
Se o nome indica "Batata", os ingredientes devem ser de batata, n√£o de peixe.
Se o nome indica "Vegano", a categoria DEVE ser vegano.

Responda APENAS com JSON v√°lido."""
        
        response = await chat.send_message(UserMessage(text=context))
        
        # Parse JSON
        response_clean = response.strip()
        if response_clean.startswith("```"):
            response_clean = response_clean.split("```")[1]
            if response_clean.startswith("json"):
                response_clean = response_clean[4:]
        response_clean = response_clean.strip()
        if response_clean.endswith("```"):
            response_clean = response_clean[:-3]
        
        try:
            result = json.loads(response_clean)
            result["ok"] = True
            result["regenerated_from_name"] = True
            return result
        except json.JSONDecodeError:
            return {
                "ok": False,
                "error": "Erro ao processar resposta da IA",
                "raw_response": response
            }
            
    except Exception as e:
        return {"ok": False, "error": str(e)}
